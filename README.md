# 본 스크립트들은 robots.txt를 준수합니다. 

# robots.txt란?
단순하게 스크래핑을 무엇을하지 말아야하는지 규정해주는 가이드라인이라 할수있습니다.  
scraping은 주로 자기가 원하는 웹사이트의 핵심 내용들을 주기적으로 뽑아야하는등에 사용됩니다.  
그리고 허락되지않은 데이터는 스크래핑하면 안됩니다.  

# 환경
colab (가격도 저렴하고 안정성이 높고 git과 driver의 연계성도 좋으며 로컬환경의 자원도 같이 사용이 가능합니다.)
